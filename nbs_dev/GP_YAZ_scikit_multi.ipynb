{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from gp_dev.core import *\n",
    "from ddop.datasets import load_yaz\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import category_encoders as ce\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, RationalQuadratic, ExpSineSquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"..\")\n",
    "path_ds = path/'datasets'\n",
    "path_res = path/'res_data'\n",
    "path_plot = path/'plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magr/anaconda3/envs/gp/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "products = ['CALAMARI', 'FISH', 'SHRIMP', 'CHICKEN', 'KOEFTE', 'LAMB', 'STEAK']\n",
    "\n",
    "for method in ['one-hot encoding', 'target encoding', ]:   \n",
    "        \n",
    "        if method == 'one-hot encoding':\n",
    "            df = load_yaz(encode_date_features=True, include_prod=None, include_date=False).frame\n",
    "        else:\n",
    "            df = load_yaz(encode_date_features=False, include_prod=None, include_date=False).frame\n",
    "        \n",
    "        # make train/val/test\n",
    "        n_train = 600\n",
    "        train_df, test_df = df.iloc[:n_train, :], df.iloc[n_train:, :]\n",
    "        n_test = len(test_df)\n",
    "        \n",
    "        train_df = pd.melt(train_df,\n",
    "             id_vars = train_df.columns.difference(products),\n",
    "             value_vars= products)\n",
    "\n",
    "        test_df = pd.melt(test_df,\n",
    "             id_vars = test_df.columns.difference(products),\n",
    "             value_vars= products) \n",
    "        \n",
    "        train_x_df, train_y_df = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "        test_x_df, test_y_df = test_df.iloc[:, :-1], test_df.iloc[:, -1]\n",
    "        \n",
    "        train_y = train_y_df.values\n",
    "        test_y = test_y_df.values\n",
    "\n",
    "        # target encoding\n",
    "        if method == 'target encoding':\n",
    "            for cat in ['WEEKDAY', 'MONTH', 'YEAR', 'ISHOLIDAY', 'WEEKEND', 'variable']:\n",
    "                encoder = ce.TargetEncoder()\n",
    "                train_x_df[cat] = encoder.fit_transform(train_x_df[cat].astype('category'), train_y_df)\n",
    "                test_x_df[cat] = encoder.transform(test_x_df[cat].astype('category'))\n",
    "        elif method == 'one-hot encoding':\n",
    "            for cat in ['variable']:\n",
    "                encoder = ce.OneHotEncoder()\n",
    "                train_x_df = pd.concat([train_x_df, encoder.fit_transform(train_x_df[cat].astype('category'), train_y_df)], axis=1).drop(columns = cat)\n",
    "                test_x_df = pd.concat([test_x_df, encoder.transform(test_x_df[cat].astype('category'))], axis=1).drop(columns = cat)\n",
    "    \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(train_x_df)\n",
    "\n",
    "        train_x = scaler.transform(train_x_df)\n",
    "        test_x = scaler.transform(test_x_df)\n",
    "\n",
    "        # Kernel with parameters given in GPML book\n",
    "        k1 = 1**2 * RBF(length_scale=0.261)  # long term smooth rising trend\n",
    "        k2 = 2.4**2 * RBF(length_scale=90.0) \\\n",
    "            * ExpSineSquared(length_scale=1.3, periodicity=1.0)  # seasonal component\n",
    "        k3 = 0.66**2 \\\n",
    "            * RationalQuadratic(length_scale=1.2, alpha=0.78) # medium term irregularity\n",
    "        k4 = 0.18**2 * RBF(length_scale=0.134) \\\n",
    "            + WhiteKernel(noise_level=1.09**2)  # noise terms\n",
    "\n",
    "        if method == 'timeseries':\n",
    "            kernel_gpml = k1 + k2 + k3 + k4\n",
    "\n",
    "        elif method == 'one-hot encoding':\n",
    "            kernel_gpml = k1 + k4\n",
    "\n",
    "        elif method == 'target encoding':\n",
    "            kernel_gpml = k1 + k4\n",
    "\n",
    "        gp = GaussianProcessRegressor(kernel=kernel_gpml, normalize_y=True)#, alpha=1)\n",
    "        gp.fit(train_x, train_y)\n",
    "\n",
    "        print(\"\\nLearned kernel: %s\" % gp.kernel_)\n",
    "        print(\"Log-marginal-likelihood: %.3f\"\n",
    "              % gp.log_marginal_likelihood(gp.kernel_.theta))\n",
    "\n",
    "        nv_means, y_std = gp.predict(test_x,  return_std=True)\n",
    "        nv_sigma = y_std\n",
    "        \n",
    "        for i, target in enumerate(products):\n",
    "            for c in range(5,100, 5):\n",
    "                cu = c/100\n",
    "                co = 1-cu\n",
    "\n",
    "                nv_solution = nv_means[i*n_test:(i+1)*n_test]+norm.ppf(cu/(cu+co))*nv_sigma[i*n_test:(i+1)*n_test]\n",
    "                cost =  np.mean([nv_cost(q, y, cu, co) for q, y in zip(nv_solution, test_y[i*n_test:(i+1)*n_test])])\n",
    "\n",
    "                ser_tmp=pd.Series({\"cu\":cu, \"co\":co, \"cost\":cost, \"type\":method, \"target\": target, \"split\": 'test'})\n",
    "                res.append(ser_tmp)\n",
    "                \n",
    "        nv_means, y_std = gp.predict(train_x,  return_std=True)\n",
    "        nv_sigma = y_std\n",
    "        \n",
    "        for i, target in enumerate(products):\n",
    "            for c in range(5,100, 5):\n",
    "                cu = c/100\n",
    "                co = 1-cu\n",
    "\n",
    "                nv_solution = nv_means[i*n_train:(i+1)*n_train]+norm.ppf(cu/(cu+co))*nv_sigma[i*n_train:(i+1)*n_train]\n",
    "                cost =  np.mean([nv_cost(q, y, cu, co) for q, y in zip(nv_solution, train_y[i*n_train:(i+1)*n_train])])\n",
    "\n",
    "                ser_tmp=pd.Series({\"cu\":cu, \"co\":co, \"cost\":cost, \"type\":method, \"target\": target, \"split\": 'train'})\n",
    "                res.append(ser_tmp)\n",
    "            #df_res = pd.DataFrame(res)\n",
    "\n",
    "for target in products:\n",
    "    method = 'saa'\n",
    "    df = load_yaz(encode_date_features=False, include_prod=[target], include_date=False).frame\n",
    "    # make train/val/test\n",
    "    n_train = 600\n",
    "    train_df, test_df = df.iloc[:n_train, :], df.iloc[n_train:, :]\n",
    "\n",
    "    train_x_df, train_y_df = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "    test_x_df, test_y_df = test_df.iloc[:, :-1], test_df.iloc[:, -1]\n",
    "\n",
    "    train_y = train_y_df.values\n",
    "    test_y = test_y_df.values\n",
    "\n",
    "    for c in range(5,100, 5):\n",
    "        cu = c/100\n",
    "        co = 1-cu\n",
    "\n",
    "        nv_quantile = np.quantile(train_y, q=cu/(cu+co))\n",
    "        cost= np.mean([nv_cost(nv_quantile, y, cu, co) for y in test_y])\n",
    "        nv_means, nv_sigma = 0,0\n",
    "\n",
    "        ser_tmp=pd.Series({\"cu\":cu, \"co\":co, \"cost\":cost, \"type\":method, \"target\": target, \"split\": 'train'})\n",
    "        res.append(ser_tmp)\n",
    "        \n",
    "df_res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnn= 'SOF_results_Symmetric.csv'\n",
    "df_tmp = pd.read_csv(nnn)\n",
    "#df_tmp = df_tmp.drop(columns=[\"Unnamed: 0\"])\n",
    "df_tmp['target']=\"STEAK\"\n",
    "df_tmp.to_csv(nnn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_res\n",
    "#df_plot = pd.read_csv('res_data/gp_all-paste.csv')\n",
    "df_plot = df_plot[~(df_plot.type.isin([\"rf_rf\", \"rf_grf\", \"rf_oracle\"]))]\n",
    "#df_plot = df_plot[~(df_plot.type.isin([\"rf_approx_risk\", \"rf_approx_sol\", \"oracle\"]))]\n",
    "#df_plot = df_plot[~(df_plot.type.isin([\"saa\", \"rf\"]))]\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.relplot(data=df_plot, x=\"cu\", y=\"cost\",col_wrap=3,facet_kws={'sharey':False},\n",
    "    col=\"target\", hue=\"type\",kind=\"line\", aspect=1, height=4); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
